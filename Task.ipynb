{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T21:06:19.478099Z",
     "start_time": "2017-08-24T21:06:16.535303Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from util import *\n",
    "from scipy.sparse import vstack, csr_matrix, coo_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import load_model\n",
    "from sklearn.utils import class_weight\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard, CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpora for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T21:06:19.497343Z",
     "start_time": "2017-08-24T21:06:19.480774Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources = {'art': [60114472, 19191317], \n",
    "           'politics': [29534144, 23482909], \n",
    "           'finances': [62438886, 81354264],\n",
    "           'strateg_management': [\"http://www.stplan.ru/\", \"http://www.30n.ru/2/1.html\"], \n",
    "           'law': [65974416, 79084019],\n",
    "           'elaboration': [\"https://vk.com/\"], \n",
    "           'industry': [67183197, 66233468], \n",
    "           'education': [30558759, 98643656],\n",
    "#            'social_business': [23509868, 56821139],\n",
    "           'charity': [],\n",
    "           'public_health': [78860407, 61490488],\n",
    "           'agriculture': [\"http://www.nsh.ru/\", \"http://россельхоз.рф/\"],\n",
    "           'government_management': [\"http://be5.biz/upravlenie/gosudarstvennoe_upravlenie.html\", 97296142],\n",
    "           'smm': [74686342, 79925455],\n",
    "           'innovations': [98643656, 63337812],\n",
    "           'safety': [37959220, 10933209],\n",
    "           'military': [\"http://www.soldiering.ru\", \"https://voennoe-delo.com\"],\n",
    "           'corporative_management': [\"http://www.cfin.ru/management/\"],\n",
    "           'social_safety': [49582956, 72388807],\n",
    "           'building': [30713157, 26978036],\n",
    "           'entrepreneurship': [69560028, 73537456],\n",
    "           'sport': [29809500, 128350290],\n",
    "           'investitions': [37876217, 3800580]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T21:06:19.626137Z",
     "start_time": "2017-08-24T21:06:19.500501Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getting data for corpora\n",
    "for tag, ids_ in sources.items():\n",
    "    path = f\"assets/corpora/{tag}.txt\"\n",
    "    s = set()\n",
    "    if not os.path.exists(path):\n",
    "        with open(path, \"w\") as f:\n",
    "            for id_ in ids_:\n",
    "                if isinstance(id_, int):\n",
    "                    wall = ParseClass.getallwall({\"owner_id\": -id_}, 1000)\n",
    "                    for post in tqdm.tqdm(wall):\n",
    "                        if len(post) and post not in s:\n",
    "                            s.add(post)\n",
    "                            _ = f.write(f\"{post}\\n\")\n",
    "                elif isinstance(id_, str):\n",
    "                    links = np.random.choice(\n",
    "                        list(ParseClass.get_all_links(id_)), 1000)\n",
    "                    for link in tqdm.tqdm(links):\n",
    "                        try:\n",
    "                            page = requests.get(link).text\n",
    "                            soup = BeautifulSoup(page, \"lxml\")\n",
    "                            for text in soup.text.strip().split(\"\\n\"):\n",
    "                                if len(text) and text not in s:\n",
    "                                    s.add(text)\n",
    "                                    _ = f.write(f\"{text}\\n\")\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-08-24T21:07:04.241Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 91/368 [1:31:56<3:37:00, 47.00s/it]  "
     ]
    }
   ],
   "source": [
    "r = ResultClass()\n",
    "for user_vk in tqdm.tqdm(social.vk.dropna()):\n",
    "    r.parse_vk(user_vk)\n",
    "    r.texts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [\"Искусство\", \"Политика\", \"Финансы\", \"Стратегическое управление\", \"Юриспруденция\", \"Исследования и разработки\",\n",
    "          \"Промышленность\", \"Образование\", \"Благотворительность\", \"Здравоохранение\", \"Сельское хозяйство\", \n",
    "          \"Государственное управление\", \"Реклама и маркетинг\", \"Инновации и модернизация\", \"Безопасность\", \n",
    "          \"Военное дело\", \"Корпоративное управление\", \"Социальная защита\", \"Строительство\", \"Предпринимательство\",\n",
    "          \"Спорт\", \"Инвестиции\"]\n",
    "norm_names = dict(zip(categories, labels))\n",
    "norm_names_reversed = dict([(a[1], a[0]) for a in norm_names.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# competencies = pd.read_csv(\"assets/competencies.csv\")\n",
    "# competencies = competencies.dropna()[['Id', 'Интересы']]\n",
    "# social = pd.read_excel(\"assets/social.xlsx\", names=['id', 'name', 'fb', 'ok', 'vk', 'email', 'twitter'])\n",
    "# accepted = social.fb.dropna().index | social.vk.dropna().index\n",
    "# social = social.loc[accepted, ['name', 'id', 'vk', 'fb']]\n",
    "# social.vk = social.vk.apply(lambda x: str(x).split(\"/\")[-1])\n",
    "# social.fb = social.fb.apply(lambda x: str(x).split(\"/\")[-1])\n",
    "# social.fb = social.fb.apply(lambda x: str(x).split(\"id=\")[-1])\n",
    "# social.fb = social.fb.apply(lambda x: str(x).split(\"?ref=\")[0])\n",
    "# social.fb = social.fb.replace('nan', np.nan)\n",
    "# social = social.merge(df[['vk', 'vk_id']], how='outer', on='vk')\n",
    "# social.vk = social.vk_id.fillna(0)\n",
    "# social = social.replace(0, np.nan).drop(labels=['vk_id'], axis=1)\n",
    "# social.set_index('id', inplace=True)\n",
    "# social = social.merge(how='inner', right=competencies, left_index=True, right_on='Id')\n",
    "# to_exclude = pd.read_csv(\"assets/known_users.csv\")['Leader-ID'].dropna().astype('int').values\n",
    "# social = social.loc[~social.Id.isin(to_exclude), :]\n",
    "# social.to_msgpack(\"assets/social.msg\")\n",
    "\n",
    "# def get_id(screen_name):\n",
    "#     try:\n",
    "#         item = vk.users.get(user_ids=screen_name)\n",
    "#         if 'deactivated' not in item:\n",
    "#             return item[0]['id']\n",
    "#     except Exception as e:\n",
    "#         print(e.args)\n",
    "# Нужно замапить screen_name с их vk_id, поэтому придется обрабатывать по одному\n",
    "\n",
    "social = pd.read_msgpack(\"assets/social.msg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels_trunc = [\"Искусство\", \"Политика\", \"Финансы\", \"Стратегическое управление\", \"Юриспруденция\", \"Исследования и разработки\",\n",
    "          \"Промышленность\", \"Образование\", \"Здравоохранение\", \"Сельское хозяйство\", \n",
    "          \"Государственное управление\", \"Реклама и маркетинг\", \"Инновации и модернизация\", \"Безопасность\", \n",
    "          \"Военное дело\", \"Корпоративное управление\", \"Социальная защита\", \"Строительство\", \"Предпринимательство\",\n",
    "          \"Инвестиции\"]\n",
    "int_labels = label_encoder.fit_transform(labels_trunc)\n",
    "\n",
    "def f(x):\n",
    "    b = []\n",
    "    for a in x.split(\",\"):\n",
    "        t = a.strip()\n",
    "        if t == \"Частный бизнес\" or t == \"Социальное предпринимательство\":\n",
    "            b.append(\"Предпринимательство\")\n",
    "        elif t == \"Дошкольное образование/детский отдых\":\n",
    "            b.append(\"Образование\")\n",
    "        elif t in {'Журналистика', 'Управление персоналом', 'Управление рисками'}:\n",
    "            pass\n",
    "        else:\n",
    "            b.append(t)\n",
    "    return b[:6]\n",
    "social.Интересы = social.Интересы.apply(f)\n",
    "def g(x):\n",
    "    if not x:\n",
    "        return np.in1d(int_labels, []).astype('int')\n",
    "    return np.in1d(int_labels, label_encoder.transform(x)).astype('int')\n",
    "social.y = social.Интересы.apply(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_competencies = []\n",
    "for nabor in social.Интересы:\n",
    "    all_competencies.extend(nabor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series(all_competencies).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-24T21:06:20.139233Z",
     "start_time": "2017-08-24T21:06:20.136015Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = list(sources.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-21T22:23:26.979577Z",
     "start_time": "2017-08-21T22:23:26.509967Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora_class = CorporaClass()\n",
    "\n",
    "for i, row in social.iterrows():\n",
    "    r = ResultClass()\n",
    "    user_vk, user_fb = row.vk, row.fb\n",
    "    if user_vk:\n",
    "        r.parse_vk(user_vk)\n",
    "    if user_fb:\n",
    "        r.parse_fb(user_fb)\n",
    "    corpora_class.add_to_corpora(r.texts, str(i))\n",
    "\n",
    "pickle.dump(corpora_class.corpora, open(\"assets/corpora.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-21T22:23:31.037693Z",
     "start_time": "2017-08-21T22:23:30.841308Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora = pickle.load(open(\"assets/corpora.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-21T22:23:31.491588Z",
     "start_time": "2017-08-21T22:23:31.484143Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpora_lengths = []\n",
    "for i, x in enumerate(corpora):\n",
    "    corpora_lengths.append(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-21T22:27:16.293951Z",
     "start_time": "2017-08-21T22:25:54.538922Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=corpora_class.full_process, max_df=0.5, sublinear_tf=True, ngram_range=(1, 2))\n",
    "docterm_matrix = vectorizer.fit_transform(list(itertools.chain(*(doc for doc in corpora))))\n",
    "\n",
    "pickle.dump(docterm_matrix, open(\"assets/docterm_matrix.p\", \"wb\"))\n",
    "pickle.dump(vectorizer, open(\"assets/vectorizer.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docterm_matrix = pickle.load(open(\"assets/docterm_matrix.p\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-21T22:27:55.742932Z",
     "start_time": "2017-08-21T22:27:55.731433Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DELIM = 1300\n",
    "NUM_OF_CLASSES = 22\n",
    "vector_size = docterm_matrix[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-22T07:33:09.877149Z",
     "start_time": "2017-08-22T07:30:42.312793Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = csr_matrix(np.empty(docterm_matrix.shape), dtype='float32')\n",
    "y = csr_matrix(social.y)\n",
    "\n",
    "ind_arr = np.cumsum(np.array(corpora_lengths))\n",
    "for c, item in enumerate(docterm_matrix):\n",
    "    # get index with needed elements\n",
    "    i = np.where(ind_arr > c)[0][0]\n",
    "    num = min(item.shape[0], DELIM)\n",
    "#     for _ in range(num):\n",
    "#         y_ = np.zeros(NUM_OF_CLASSES)\n",
    "#         y_[i] = 1\n",
    "#     y[c] = y_\n",
    "#     y[c] = i\n",
    "    X[c] = item[:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-22T07:33:10.526660Z",
     "start_time": "2017-08-22T07:33:09.915155Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.toarray()\n",
    "y = y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-22T07:33:14.537199Z",
     "start_time": "2017-08-22T07:33:10.535161Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-22T07:30:08.242682Z",
     "start_time": "2017-08-22T07:30:07.948297Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_vec = Input(shape=(vector_size,))\n",
    "l1 = Dense(96, activation='relu')(input_vec)\n",
    "l2 = Dense(18, activation='relu')(l1)\n",
    "l3 = Dropout(0.15)(l2)\n",
    "l4 = Dense(64, activation='sigmoid')(l3)\n",
    "output = Dense(NUM_OF_CLASSES, activation='sigmoid')(l4)\n",
    "\n",
    "classifier = Model(input_vec, output)\n",
    "classifier.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-22T07:30:13.314818Z",
     "start_time": "2017-08-22T07:30:11.074875Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17233 samples, validate on 4309 samples\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Received a label value of 21 which is outside the valid range of [0, 1).  Label values: 4 6 12 19 5 18 12 5 20 12 12 8 19 10 20 12 12 12 17 14 10 12 12 12 20 13 8 13 5 19 4 18 10 20 10 7 19 1 14 19 19 10 8 10 2 8 12 18 19 2 14 1 17 8 17 19 20 12 20 18 12 19 10 18 18 12 4 17 17 5 12 6 6 17 4 12 3 12 19 12 8 18 3 17 19 17 12 12 6 12 20 17 7 10 16 4 4 10 16 17 12 10 10 6 12 19 13 2 12 16 12 13 17 6 15 5 12 10 7 20 7 12 10 0 18 8 17 19 12 5 16 12 20 10 5 8 18 12 9 11 6 4 17 1 1 6 21 18 20 17 4 19 8 17 12 12 12 20 5 12 12 3 12 1 7 8 19 20 1 12 6 19 21 3 18 12 10 19 13 8 12 11 13 10 7 4 12 8 12 7 18 2 8 11 8 17\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Reshape_1, Cast_4)]]\n\nCaused by op 'SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits', defined at:\n  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-72-7f12b39e75e7>\", line 9, in <module>\n    classifier.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy', metrics=['categorical_accuracy'])\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/training.py\", line 840, in compile\n    sample_weight, mask)\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/training.py\", line 446, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"/usr/local/lib/python3.6/site-packages/keras/losses.py\", line 53, in sparse_categorical_crossentropy\n    return K.sparse_categorical_crossentropy(y_pred, y_true)\n  File \"/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2782, in sparse_categorical_crossentropy\n    logits=logits)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1690, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2486, in _sparse_softmax_cross_entropy_with_logits\n    features=features, labels=labels, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Received a label value of 21 which is outside the valid range of [0, 1).  Label values: 4 6 12 19 5 18 12 5 20 12 12 8 19 10 20 12 12 12 17 14 10 12 12 12 20 13 8 13 5 19 4 18 10 20 10 7 19 1 14 19 19 10 8 10 2 8 12 18 19 2 14 1 17 8 17 19 20 12 20 18 12 19 10 18 18 12 4 17 17 5 12 6 6 17 4 12 3 12 19 12 8 18 3 17 19 17 12 12 6 12 20 17 7 10 16 4 4 10 16 17 12 10 10 6 12 19 13 2 12 16 12 13 17 6 15 5 12 10 7 20 7 12 10 0 18 8 17 19 12 5 16 12 20 10 5 8 18 12 9 11 6 4 17 1 1 6 21 18 20 17 4 19 8 17 12 12 12 20 5 12 12 3 12 1 7 8 19 20 1 12 6 19 21 3 18 12 10 19 13 8 12 11 13 10 7 4 12 8 12 7 18 2 8 11 8 17\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Reshape_1, Cast_4)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Received a label value of 21 which is outside the valid range of [0, 1).  Label values: 4 6 12 19 5 18 12 5 20 12 12 8 19 10 20 12 12 12 17 14 10 12 12 12 20 13 8 13 5 19 4 18 10 20 10 7 19 1 14 19 19 10 8 10 2 8 12 18 19 2 14 1 17 8 17 19 20 12 20 18 12 19 10 18 18 12 4 17 17 5 12 6 6 17 4 12 3 12 19 12 8 18 3 17 19 17 12 12 6 12 20 17 7 10 16 4 4 10 16 17 12 10 10 6 12 19 13 2 12 16 12 13 17 6 15 5 12 10 7 20 7 12 10 0 18 8 17 19 12 5 16 12 20 10 5 8 18 12 9 11 6 4 17 1 1 6 21 18 20 17 4 19 8 17 12 12 12 20 5 12 12 3 12 1 7 8 19 20 1 12 6 19 21 3 18 12 10 19 13 8 12 11 13 10 7 4 12 8 12 7 18 2 8 11 8 17\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Reshape_1, Cast_4)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-78200db8fc38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m196\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;31m#                callbacks=callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m               )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Received a label value of 21 which is outside the valid range of [0, 1).  Label values: 4 6 12 19 5 18 12 5 20 12 12 8 19 10 20 12 12 12 17 14 10 12 12 12 20 13 8 13 5 19 4 18 10 20 10 7 19 1 14 19 19 10 8 10 2 8 12 18 19 2 14 1 17 8 17 19 20 12 20 18 12 19 10 18 18 12 4 17 17 5 12 6 6 17 4 12 3 12 19 12 8 18 3 17 19 17 12 12 6 12 20 17 7 10 16 4 4 10 16 17 12 10 10 6 12 19 13 2 12 16 12 13 17 6 15 5 12 10 7 20 7 12 10 0 18 8 17 19 12 5 16 12 20 10 5 8 18 12 9 11 6 4 17 1 1 6 21 18 20 17 4 19 8 17 12 12 12 20 5 12 12 3 12 1 7 8 19 20 1 12 6 19 21 3 18 12 10 19 13 8 12 11 13 10 7 4 12 8 12 7 18 2 8 11 8 17\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Reshape_1, Cast_4)]]\n\nCaused by op 'SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits', defined at:\n  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-72-7f12b39e75e7>\", line 9, in <module>\n    classifier.compile(optimizer='adadelta', loss='sparse_categorical_crossentropy', metrics=['categorical_accuracy'])\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/training.py\", line 840, in compile\n    sample_weight, mask)\n  File \"/usr/local/lib/python3.6/site-packages/keras/engine/training.py\", line 446, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"/usr/local/lib/python3.6/site-packages/keras/losses.py\", line 53, in sparse_categorical_crossentropy\n    return K.sparse_categorical_crossentropy(y_pred, y_true)\n  File \"/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2782, in sparse_categorical_crossentropy\n    logits=logits)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 1690, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2486, in _sparse_softmax_cross_entropy_with_logits\n    features=features, labels=labels, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Received a label value of 21 which is outside the valid range of [0, 1).  Label values: 4 6 12 19 5 18 12 5 20 12 12 8 19 10 20 12 12 12 17 14 10 12 12 12 20 13 8 13 5 19 4 18 10 20 10 7 19 1 14 19 19 10 8 10 2 8 12 18 19 2 14 1 17 8 17 19 20 12 20 18 12 19 10 18 18 12 4 17 17 5 12 6 6 17 4 12 3 12 19 12 8 18 3 17 19 17 12 12 6 12 20 17 7 10 16 4 4 10 16 17 12 10 10 6 12 19 13 2 12 16 12 13 17 6 15 5 12 10 7 20 7 12 10 0 18 8 17 19 12 5 16 12 20 10 5 8 18 12 9 11 6 4 17 1 1 6 21 18 20 17 4 19 8 17 12 12 12 20 5 12 12 3 12 1 7 8 19 20 1 12 6 19 21 3 18 12 10 19 13 8 12 11 13 10 7 4 12 8 12 7 18 2 8 11 8 17\n\t [[Node: SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Reshape_1, Cast_4)]]\n"
     ]
    }
   ],
   "source": [
    "# callbacks = [EarlyStopping(monitor='val_acc',\n",
    "#                            patience=8,\n",
    "#                            verbose=1,\n",
    "#                            min_delta=1e-4,\n",
    "#                            mode='max'),\n",
    "#              ReduceLROnPlateau(monitor='val_acc',\n",
    "#                                factor=0.1,\n",
    "#                                patience=4,\n",
    "#                                verbose=1,\n",
    "#                                epsilon=1e-4,\n",
    "#                                mode='max'),\n",
    "#              ModelCheckpoint(monitor='val_acc',\n",
    "#                              filepath='assets/vk_texts_classifier.h5',\n",
    "#                              save_best_only=True,\n",
    "#                              save_weights_only=False,\n",
    "#                              mode='max'),\n",
    "#              # TensorBoard(log_dir='logs'),\n",
    "#              CSVLogger('assets/last_training_log.csv', separator=',', append=False)\n",
    "#             ]\n",
    "\n",
    "# classifier.load_weights('vk_texts_classifier.h5')\n",
    "classifier.fit(X_train, \n",
    "               y_train, \n",
    "               validation_data=(X_test, y_test), \n",
    "               batch_size=196, \n",
    "               epochs=75, \n",
    "               class_weight='balanced'\n",
    "#                callbacks=callbacks\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T22:03:48.894279Z",
     "start_time": "2017-08-20T22:03:48.725052Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.save(\"assets/vk_texts_classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T22:03:49.087675Z",
     "start_time": "2017-08-20T22:03:48.902935Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# social = pd.read_excel(\"social.xlsx\", names=['id', 'name', 'fb', 'ok', 'vk', 'email', 'twitter'])\n",
    "# social.set_index('id', inplace=True)\n",
    "# social = social[social.vk.notnull()]\n",
    "# social.vk = social.vk.apply(lambda x: str(x).split(\"/\")[-1])\n",
    "# df = social[social.vk.notnull()]\n",
    "# df = df[['name', 'vk']]\n",
    "\n",
    "# def get_id(screen_name):\n",
    "#     try:\n",
    "#         item = vk.users.get(user_ids=screen_name)\n",
    "#         if 'deactivated' not in item:\n",
    "#             return item[0]['id']\n",
    "#     except Exception as e:\n",
    "#         print(e.args)\n",
    "# # Нужно замапить screen_name с их vk_id, поэтому придется обрабатывать по одному\n",
    "\n",
    "# df['vk_id'] = df.vk.progress_apply(get_id)\n",
    "# df.dropna(inplace=True)\n",
    "# df.vk_id = df.vk_id.astype('int')\n",
    "# df.to_msgpack(\"df.msg\")\n",
    "df = pd.read_msgpack(\"assets/df.msg\")\n",
    "known = pd.read_csv(\"assets/known_users.csv\")\n",
    "known = known.merge(df[['vk_id']], left_on='Leader-ID', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T22:03:52.800876Z",
     "start_time": "2017-08-20T22:03:49.091638Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_class = ResultClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-21T19:27:59.681431Z",
     "start_time": "2017-08-21T19:26:55.594742Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 324.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1964.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1630.76it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 781.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 430.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1848.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 553.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 705.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3010.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2857.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2281.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 155.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1901.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 22.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1416.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2309.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1886.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 585.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 8473.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 549.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5315.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 66.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 687.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3404.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2257.43it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1529.09it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 260.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 677.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 678.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 823.87it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1283.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 569.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1037.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 673.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 681.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1461.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 319.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 689.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 286.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 608.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 287.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 768.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 911.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 217.30it/s]\n"
     ]
    }
   ],
   "source": [
    "categories = json.load(open(\"assets/categories.json\"))\n",
    "classifier = load_model(\"assets/vk_texts_classifier.h5\")\n",
    "vectorizer = pickle.load(open(\"assets/vectorizer.p\", \"rb\"))\n",
    "\n",
    "with open(\"t.txt\", \"w\") as f:\n",
    "    for user_fb in known.FB:\n",
    "        user_vk = None\n",
    "        texts = []\n",
    "        parse_class = ParseClass()\n",
    "        if user_vk:\n",
    "            texts.extend(parse_class.process_owner_vk(user_vk, owner_type='user'))\n",
    "            public_ids = parse_class.get_publics(user_vk, 6)\n",
    "            for public_id in public_ids:\n",
    "                texts.extend(parse_class.process_owner_vk(public_id, owner_type='public', n_wall=2000))\n",
    "        if user_fb:\n",
    "            # texts.extend(parse_class.get_posts_fb(user_fb))\n",
    "            texts.extend(parse_class.get_posts_fb_temp(user_fb))\n",
    "        corpora_class = CorporaClass()\n",
    "        corpora_class.add_to_corpora(texts)\n",
    "        corpora_class.process_corpora()\n",
    "        pred = categories[svm.predict(vectorizer.transform([\" \".join(corpora_class.corpora[0])]).toarray())[0]]\n",
    "        _ = f.write(f\"{known.loc[known.FB == user_fb, 'ФИ']} – {pred}\")\n",
    "    #     verdict = normalize(np.sum(svm.predict(vectorizer.transform(corpora_class.corpora[0]).toarray()),\n",
    "    #                                axis=0).reshape(1, -1))[0]\n",
    "    #     list(zip(categories, verdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T22:09:40.704017Z",
     "start_time": "2017-08-20T22:03:52.819177Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/44 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/44 [00:02<01:55,  2.69s/it][A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|▍         | 2/44 [00:03<01:24,  2.01s/it]]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|▋         | 3/44 [00:03<01:00,  1.47s/it]]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|▉         | 4/44 [00:04<01:00,  1.52s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 11%|█▏        | 5/44 [00:06<00:59,  1.51s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▎        | 6/44 [00:06<00:44,  1.18s/it]]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 16%|█▌        | 7/44 [00:07<00:34,  1.06it/s]]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 18%|█▊        | 8/44 [00:09<00:42,  1.18s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 9/44 [00:09<00:32,  1.07it/s]]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 23%|██▎       | 10/44 [00:09<00:27,  1.24it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 11/44 [00:10<00:21,  1.53it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 27%|██▋       | 12/44 [00:59<08:10, 15.32s/it]A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 30%|██▉       | 13/44 [01:00<05:39, 10.97s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 32%|███▏      | 14/44 [01:01<03:59,  7.99s/it][A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 34%|███▍      | 15/44 [01:01<02:45,  5.71s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 36%|███▋      | 16/44 [01:02<01:53,  4.07s/it]]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 39%|███▊      | 17/44 [01:02<01:21,  3.01s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 41%|████      | 18/44 [01:03<01:00,  2.33s/it][A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 43%|████▎     | 19/44 [01:03<00:43,  1.72s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 45%|████▌     | 20/44 [01:06<00:47,  1.99s/it][A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 48%|████▊     | 21/44 [01:06<00:34,  1.51s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\u001b[A\n",
      " 50%|█████     | 22/44 [03:04<13:19, 36.36s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 52%|█████▏    | 23/44 [03:06<09:04, 25.95s/it][A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 55%|█████▍    | 24/44 [03:06<06:05, 18.27s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 57%|█████▋    | 25/44 [03:06<04:06, 12.95s/it][A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 59%|█████▉    | 26/44 [03:07<02:44,  9.15s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 61%|██████▏   | 27/44 [03:09<02:00,  7.11s/it][A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 64%|██████▎   | 28/44 [03:10<01:22,  5.17s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 66%|██████▌   | 29/44 [03:11<01:00,  4.03s/it][A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 68%|██████▊   | 30/44 [03:12<00:44,  3.18s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 70%|███████   | 31/44 [03:13<00:29,  2.31s/it]]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 73%|███████▎  | 32/44 [03:14<00:24,  2.03s/it][A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 75%|███████▌  | 33/44 [03:14<00:16,  1.51s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 77%|███████▋  | 34/44 [03:16<00:14,  1.50s/it][A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 80%|███████▉  | 35/44 [03:17<00:12,  1.41s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 82%|████████▏ | 36/44 [03:18<00:10,  1.26s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 84%|████████▍ | 37/44 [03:20<00:10,  1.48s/it][A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 86%|████████▋ | 38/44 [03:21<00:08,  1.40s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 89%|████████▊ | 39/44 [03:22<00:06,  1.40s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 91%|█████████ | 40/44 [03:24<00:05,  1.42s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 93%|█████████▎| 41/44 [03:25<00:04,  1.45s/it][A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 95%|█████████▌| 42/44 [03:27<00:02,  1.44s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      " 98%|█████████▊| 43/44 [03:28<00:01,  1.39s/it]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 44/44 [05:47<00:00, 42.72s/it]A\n"
     ]
    }
   ],
   "source": [
    "offset = 0\n",
    "for index, row in tqdm.tqdm(known.iloc[offset:, :].iterrows(), total=len(known) - offset):\n",
    "    user_vk = row['vk_id']\n",
    "    if np.isnan(user_vk):\n",
    "        user_vk = None\n",
    "    user_fb = row['FB']\n",
    "    try:\n",
    "        verdict = result_class.get_result(user_vk, user_fb)\n",
    "        for cat, value in verdict:\n",
    "            known.loc[index, cat] = value\n",
    "    except ValueError:\n",
    "        for cat in categories:\n",
    "            known.loc[index, cat] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T22:09:41.393051Z",
     "start_time": "2017-08-20T22:09:40.707694Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_dict = {\"values\": []}\n",
    "for name in known.ФИ:\n",
    "    results = []\n",
    "    for col in known[known.ФИ == name].iloc[:, 4:].columns:\n",
    "        results.append({\"name\": norm_names[col], \"value\": float(known.loc[known.ФИ == name, col].values[0])})\n",
    "    norm_dict['values'].append({\"name\": name, \"results\": results})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T22:09:41.567596Z",
     "start_time": "2017-08-20T22:09:41.401472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Искусство', 0.014755845)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Политика', 0.026561856)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Финансы', 0.039396241)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Стратегическое управление', 0.039121598)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Юриспруденция', 0.071112327)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Исследования и разработки', 0.088504076)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Промышленность', 0.29107782)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Образование', 0.62175745)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Благотворительность', 0.10370329)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Здравоохранение', 0.052846637)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Сельское хозяйство', 0.032095235)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Государственное управление', 0.026598753)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Реклама и маркетинг', 0.064131789)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Инновации и модернизация', 0.16241147)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Безопасность', 0.025394594)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Военное дело', 0.017704837)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Корпоративное управление', 0.1330671)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Социальная защита', 0.12280205)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Строительство', 0.060238123)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Предпринимательство', 0.1269815)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Спорт', 0.10918298)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "('Инвестиции', 0.026866633)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in known.iloc[:, 4:].columns:\n",
    "    norm_names[col], known.loc[:, col].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-21T17:18:24.341722Z",
     "start_time": "2017-08-21T17:18:24.271307Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Открылись!!!! Приветствуем Точку кипения в Петрозаводске!\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-32a930bbfe36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mknown\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FB'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"End of file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-32a930bbfe36>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mknown\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FB'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"End of file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "for fb in known.loc[known['education'] < 0.1, 'FB']:\n",
    "    with open(f\"assets/corpora_cached_fb_users/{fb}.txt\") as f:\n",
    "        for line in f:\n",
    "            print(line)\n",
    "    print([a.values for a in known.loc[known['FB'] == fb, :].items()])\n",
    "    print(\"End of file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T22:09:41.631117Z",
     "start_time": "2017-08-20T22:09:41.570307Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "known.to_csv(\"assets/known.csv\")\n",
    "json.dump(norm_dict, open(\"assets/temporary_result.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T22:09:41.691154Z",
     "start_time": "2017-08-20T22:09:41.651791Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import vk_api\n",
    "from config import VK_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T22:09:41.764581Z",
     "start_time": "2017-08-20T22:09:41.722894Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vk = vk_api.VkApi(token=VK_TOKEN)\n",
    "vk = vk.get_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T22:09:43.840139Z",
     "start_time": "2017-08-20T22:09:41.768188Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = [a['text'] for a in vk.newsfeed.search(q=\"корпоративное управление\", count=200)['items']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-20T22:09:43.864179Z",
     "start_time": "2017-08-20T22:09:43.843135Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('t.txt', 'w') as f:\n",
    "    for line in t:\n",
    "        _ = f.write(f'{line}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
